---
description: Rhode Island's official evaluation framework for support professionals (school counselors, psychologists, SLPs, social workers, library/reading/math specialists, etc.). Details summative/cyclical evaluation requirements, observation protocols, professional practice rubrics, student learning objectives, and final effectiveness rating calculations using weighted measures (25% collaboration, 25% service delivery, 20% responsibilities, 30% student learning).
type: guide
---

# Rhode Island Model Evaluation & Support System - Support Professional Edition IV

## Table of Contents

- Introduction
- Rhode Island Model at a Glance
- Evaluation Frequency
- System Overview
- Support and Development
- Professional Practice (Collaboration & Service Delivery)
- Professional Responsibilities
- Measures of Student Learning
- Calculating a Final Effectiveness Rating
- Appendices

---

## Introduction

Rhode Island is committed to ensuring that all educators receive fair, accurate, and meaningful educator evaluations that provide information that can help all support professionals improve and refine their practice. This commitment is an outgrowth of our recognition of the influence support professionals have on student growth and achievement. Currently, LEAs in Rhode Island may submit a district-designed model for approval that complies with the Educator Evaluation System Standards or adopt the Rhode Island Model Support Professional Evaluation and Support System (Rhode Island Model).

This document describes the process and basic requirements for the Rhode Island Model Support Professional Evaluation and Support System. Through this model, we hope to help create a culture where all support professionals have a clear understanding of what defines excellence in their work; receive prioritized, specific, and actionable feedback about their performance; and receive support to continuously improve their effectiveness, regardless of the number of years they have been working.

### How to Use the Guidebook

In this guidebook we clearly separate and label aspects of the model that local education agencies (LEAs) can customize as **Flexibility Factors**. Throughout the guidebook, we indicate corresponding resources available on the RIDE website. These resources aim to help educators understand how to best implement various aspects of the Rhode Island Model. Resources include online training modules, sample Student Learning/Outcome Objectives, and a suite of calibration protocols designed to help school and LEA leaders facilitate ongoing calibration exercises.

> **Flexibility Factor**
>
> Boxes like this one will be used throughout the guidebook to highlight where schools and LEAs have an opportunity to customize aspects of the Rhode Island Model and establish policies to meet their local needs.

### Selecting the Appropriate Model

We recognize that support professional roles may look different in different contexts. The Rhode Island Model Support Professional Evaluation and Support System should be used to evaluate library media specialists*, school nurse teachers*, reading specialists/consultants*, mathematics specialists/consultants*, English as a second language specialists/consultants*, instructional leaders*, school counselors, school psychologists, speech language pathologists, and school social workers. Using this system for any other role is not recommended.

*For individuals who spend time instructing students, the Teacher Evaluation and Support System may be a better fit. This is an LEA decision in consideration of alignment to specific local responsibilities.

---

## Rhode Island Model at a Glance

### Requirements for Support Professionals in the Summative Evaluation Year

The table below outlines the minimum requirements for support professionals receiving a full evaluation.

| Element | Minimum Requirements |
|---------|---------------------|
| **Evaluation Conferences** | Three conferences between the support professional and the evaluator (beginning-of-year, middle-of-year and end-of-year) |
| **Professional Practice** | • At least three observations (one announced at least a week in advance and two unannounced) of at least 20 minutes each and evidence gathered through day to day interactions<br>• Written feedback after each observation |
| **Professional Responsibilities** | Holistic ratings on each of the seven components of the Professional Responsibilities Rubric based on evidence collected throughout the year |
| **Professional Growth Goal** | One Professional Growth Goal written at the beginning of the year and scored by the evaluator at the end of the year |
| **Student Learning** | At least two but no more than four SLOs/SOOs using either the original or flex models |
| **Final Effectiveness Rating** | Calculated using the points-based system, with each measure having the following weights:<br>• Professional Practice: Collaboration (25 percent)<br>• Professional Practice: Service Delivery (25 percent)<br>• Professional Responsibilities (20 percent)<br>• Student Learning (30 percent) |
| **Performance Improvement Plans** | Development and implementation of a Performance Improvement Plan for any support professional receiving a FER of Developing or Ineffective as defined in Standard Four of the Educator Evaluation System Standards |

### Requirements for Support Professionals in the Cyclical Process

Support professionals in the cyclical process at a minimum must have an annual conference with their evaluator.

---

## Evaluation Frequency

The table below identifies how frequently support professionals must be evaluated.

| Support professionals who… | Evaluation Frequency |
|---------------------------|---------------------|
| Received a Final Effectiveness Rating of **Highly Effective** on their most recent evaluation | No more than once every three years |
| Received a Final Effectiveness Rating of **Effective** on their most recent evaluation | No more than once every two years |
| Received a Final Effectiveness Rating of **Developing** on their most recent evaluation | Annually |
| Received a Final Effectiveness Rating of **Ineffective** on their most recent evaluation | Annually |
| Do not have tenure | Annually |
| Are using a different certificate in their current placement than they were during their most recent evaluation | Annually |
| Received no rating in the prior year | Annually |

### When Can Evaluations Be Conducted More Frequently?

- An LEA may provide more frequent evaluations than stipulated above as part of a negotiated collective bargaining agreement.
- If concerns arise about a tenured support professional's performance, the support professional may receive more frequent evaluations so long as actions are in accordance with the negotiated collective bargaining agreement. Triggers for more frequent evaluations may include, but are not limited to, informal classroom walkthroughs, professional conduct, and measures of student learning.

### Annual Conferences

All educators who received a rating of Highly Effective and Effective and are in a non-summative year should have an annual conference. The conference should be in accordance with a process and scope determined by the district educator evaluation committee (DEC). The purposes of these conferences may include but are not limited to the following:

- Feedback on classroom walkthroughs
- Discussions about other local student learning measures
- Other feedback that will assist with professional growth and the improvement of practice and student learning

---

## System Overview

### Evaluation Criteria

The Rhode Island Model relies on multiple measures to paint a fair, accurate, and comprehensive picture of a support professional's performance. All support professionals will be evaluated on four measures.

1. **Professional Practice: Collaboration** – This measure includes four components focused on how support professionals work with colleagues, administrators, students, families, and community organizations to meet the needs of students.

2. **Professional Practice: Service Delivery** – This measure includes four components focused on the services, supports, data use, programming, and consultation provided by a support professional.

3. **Professional Responsibilities** – This measure assesses the contributions support professionals make as members of their learning community as defined in the Professional Responsibilities Rubric.

4. **Student Learning** – This measure assesses the support professional's impact on student learning through the use of Student Learning Objectives (SLOs) and/or Student Outcome Objectives (SOOs).

Scores from each of the four measures combine to produce a Final Effectiveness Rating of **Highly Effective, Effective, Developing, or Ineffective**.

[Image: Pie chart showing the breakdown of Final Effectiveness Rating components:
- Professional Practice: Collaboration 25%
- Professional Practice: Service Delivery 25%
- Professional Responsibilities 20%
- Student Learning 30%]

### Performance Level Descriptors

Each of the four Final Effectiveness Ratings has an associated performance level descriptor that provides a general description of what the rating is intended to mean, with the acknowledgement that exceptions do exist. Performance level descriptors can help clarify expectations and promote a common understanding of the differences between the final effectiveness ratings of Highly Effective, Effective, Developing, and Ineffective. Additional information about how to interpret the ratings is available by examining the detailed scoring rubrics and related evaluation materials.

**Highly Effective** – A Highly Effective rating indicates outstanding performance by the support professional. A support professional who earns a Highly Effective rating has a very high, positive impact on student outcomes and exhibits high-quality professional behaviors regarding service delivery and professional responsibilities.

**Effective** – An Effective rating indicates consistently strong performance by the support professional. A support professional who earns an Effective rating has a high, positive impact on student outcomes and exhibits high-quality professional behaviors regarding service delivery and professional responsibilities.

**Developing** – A Developing rating indicates inconsistent performance or consistently moderate performance by the support professional. A support professional who earns a Developing rating has one aspect much weaker than the other (either impact on the student outcomes or professional behaviors), or is consistently moderate in both.

**Ineffective** – An Ineffective rating indicates consistently low performance by the support professional. A support professional who earns an Ineffective rating has a low or negative impact on student outcomes and exhibits low quality professional behaviors regarding service delivery and professional responsibilities.

---

## Primary and Complementary Evaluators

All support professionals are required to have a primary evaluator who is responsible for the overall evaluation process, including assigning final ratings. In many cases the primary evaluator will be the principal, assistant principal, director of pupil personnel, or special education director, but schools and LEAs are encouraged to think strategically about who is best positioned to evaluate the various support professional roles. Considering the holistic nature of the evaluation process, it is important that evaluators have the capacity to observe and interact with the support professional on a regular basis.

Some LEAs may also decide to use complementary evaluators to assist primary evaluators (e.g., help collect evidence and provide feedback). Like primary evaluators, complementary evaluators are required to give support professionals written feedback after observations. A complementary evaluator should share his or her feedback with the primary evaluator as it is collected and shared with support professionals. Primary evaluators will have sole responsibility for assigning final ratings.

> **Flexibility Factor - Evaluators**
>
> - Schools/LEAs have the flexibility to decide who will serve as the primary evaluator.
> - LEA policy or the local collective bargaining agreement may allow for the use of complementary evaluators.
> - Schools and LEAs may also choose to select individuals based within or outside the school or LEA in which they serve as evaluators. The complementary evaluator could be a single peer evaluator or a team of peer evaluators.

### Ensuring Fairness and Accuracy

To help ensure fairness and accuracy, the Rhode Island Model uses multiple measures to assess performance. According to the Educator Evaluation System Standards LEAs will:

- Ensure that all evaluators receive comprehensive training and opportunities for calibration, thus promoting demonstration of valid and accurate judgments.
- Provide ongoing training on the evaluation system to all educators.
- Collect and analyze evaluation data to identify individual and collective professional development needs.
- Provide opportunities for educators to participate in professional development that meets these individual and collective professional development needs.
- Provide intensive support to educators new to the profession, educators new to a certificate area, educators new to the LEA, and educators who do not meet expectations for educator quality.
- Identify the ways in which evaluation data are used to demonstrate each of the four levels of effectiveness and the actions that result from each rating.
- Ensure that the LEA evaluation committee regularly reviews the system and engages in activities to maintain and improve the evaluation system, such as strategic planning, planning professional development, assuring adequate resources, analyzing data and recommending changes, and assessing fidelity of implementation.

---

## Support and Development

Every school is unique, and support and development should not look exactly the same for everyone. However, the Rhode Island Model is designed to foster support professional development by:

- **Outlining high expectations** that are clear and aligned with school, LEA, and state priorities.
- **Establishing a common vocabulary** for meeting expectations.
- **Encouraging student-focused conversations** to share best practices and address common challenges.
- **Grounding support professional learning** in data-driven collaboration, conferencing, observation, and feedback to meet shared goals for student achievement.
- **Providing a reliable process** for support professionals to focus practice and drive student learning.

### Evaluation Conferences (Beginning/Middle/End)

The three evaluation conferences represent opportunities for honest, data-driven conversations focused on promoting continuous improvement.

**Beginning-of-Year Conference:** The support professional and evaluator discuss the support professional's past performance, Professional Growth Goal, student learning, how they will be observed, how confidential situations will be handled, and the year ahead. When discussing the SLOs/SOOs, support professionals and evaluators can improve transparency of expectations by making sure they share a common understanding of the criteria for Not Met, Nearly Met, Met, and Exceeded.

**Mid-Year Conference:** The support professional and evaluator discuss all aspects of the support professional's performance to date. Discussions should address Professional Practice: Collaboration, Professional Practice: Service Delivery, Professional Responsibilities, and Student Learning. In some cases, Professional Growth Goals and SLOs/SOOs may be revised based on discussion between the support professional and evaluator. For example, a support professional with high mobility may need to compare the current roster to the one used to set targets. If there are substantial differences, adjustments to the target may be necessary to include all students on the most recent caseload and exclude students who are no longer on the caseload.

While Final Effectiveness Ratings are not determined until the end of the evaluation cycle, the Mid-Year Conference is an important point in the year when specific concerns should be addressed, especially if they indicate that a support professional's impact on student learning is below expectations. Support professionals should already be aware of specific concerns through observation feedback and prior documentation so that they are not addressed for the first time at the conference. If the support professional is struggling, and has not started an Improvement Plan by the time of the Mid-Year Conference, this is an opportunity to craft an initial plan together.

**End-of-Year Conferences:** The support professional and evaluator review summative feedback on Professional Practice and Responsibilities and discuss student learning results. They also discuss progress toward the support professional's Professional Growth Goal. During or soon after the conference, the evaluator finalizes and shares the Support Professional's Final Effectiveness rating for the school year.

> **Flexibility Factor - Evaluation Conferences**
>
> - The length of each conference is decided at the local level, though we recommend at least 15 minutes per conference. Conference length should match the purpose of the conference to meet stated goals.
> - Beginning-of-Year Conferences may be held in groups, such as by team or content area, in order to collaborate around student learning and PGGs. A support professional may request an individual conference to address personal goals or concerns.

---

## Performance Improvement Plans

The goal of the Performance Improvement Plan is to ensure that support professionals who are in need of support receive it. A support professional who has a Performance Improvement Plan works with an improvement team to develop the plan. An improvement team may consist solely of the support professional's evaluator or of multiple people, depending on the support professional's needs and the school and LEA context.

### Required Components of Performance Improvement Plans

Any support professional who receives a Final Effectiveness Rating of Developing or Ineffective must have a Performance Improvement Plan the following year.

Performance Improvement Plans must:

- Include time-bound goals, action steps, and benchmarks.
- Identify action steps the support professional will take to improve his or her practice.
- Clearly identify who is responsible for implementing each aspect of the plan.
- Plan for frequent check-ins with the evaluator or other support personnel.

The Educator Evaluation System Standards require LEAs to establish personnel policies that use evaluation information to inform decisions. A support professional who does not demonstrate sufficient improvement may be subject to personnel actions, according to local policies.

> **Flexibility Factor - Performance Improvement Plans**
>
> An evaluator may put a support professional on a Performance Improvement Plan at any time during the year if concerns arise. This applies to all support professional regardless of their status in the cyclical process.

---

## Professional Practice: Collaboration & Service Delivery

The Professional Practice Rubric (Appendix 3) represents the Rhode Island Model's definition of effective service delivery. More specifically:

- The Professional Practice Rubric aligns with the professional standards of support professional roles.
- The Professional Practice Rubric is a holistic scoring tool, not an in-person assessment or conference tool. Evaluators should use the Professional Practice and Responsibilities feedback form to deliver feedback at least three times during the school year.
- The Professional Practice Rubric consists of eight components organized into two domains.
- Evaluators score components holistically according to the rubric at the end of the school year, based on evidence collected during the entire school year, although evaluators have the flexibility to provide formative scores at the mid-year.

### Professional Practice Rubric Components

| Professional Practice: Collaboration Domain 1 | Professional Practice: Service Delivery Domain 2 |
|----------------------------------------------|----------------------------------------------|
| **1a:** Works with educators and families to develop strategies and resources to meet the needs of students | **2a:** Establishes service delivery and/or program goals and develops a plan to evaluate them |
| **1b:** Uses and models effective communication with learners, colleagues and/or stakeholders | **2b:** Plans effectively for service delivery that is based on student data and knowledge of child development |
| **1c:** Builds rapport with students promoting effective implementation of services | **2c:** Implements service delivery that is student focused ensuring students have greater ownership in their education and well being |
| **1d:** Demonstrates flexibility and responsiveness | **2d:** Uses appropriate assessments to diagnose or identify and monitor student issues or programmatic progress and to adjust service/program delivery |

---

## Assessing Professional Practice

The evaluator should assess professional practice using evidence from both natural interactions and observations. It is recommended that evaluators divide the school year into three segments, with each segment culminating in an observation. Evaluators should collect evidence from natural interactions throughout the segment in order to be able to assess consistency of practice over time.

For support professional observations, an evaluator could observe a support professional during activities such as meetings, student group sessions, or during instructional time (depending on the specific role). The goal is to see the support professional in an authentic situation that is part of their role.

The basic requirements for observing a support professional include:

- At least one announced observation, and at least two unannounced for a minimum of three
- Written feedback is required after each observation

### Feedback

High-quality feedback helps support professionals improve by identifying strengths (practices they should continue) and areas for improvement (changes to their practice that should be prioritized). To be effective, feedback based on observations and natural interactions should be prioritized, specific, actionable, delivered with a supportive tone, and provided to the support professional as soon after the observation as possible. Feedback should address Professional Practice: Collaboration, Professional Practice: Service Delivery, and Professional Responsibilities.

### Confidentiality Considerations

Many support professionals handle sensitive issues where student and family privacy must be protected by law. This is particularly a consideration with health and mental health related professions (school counselors, school nurse teachers, school psychologists, and school social workers). It is important for evaluators and support professionals to determine a plan at the beginning of the year for how to handle these confidentiality issues for evaluation purposes. For instance, in a scenario where a support professional is working with a student in crisis or another sensitive issue, it is important for the support professional to prioritize the student he or she is working with and arrange a different time for an evaluator to return for an observation. Evaluators and support professionals should always prioritize student well-being when deciding upon appropriate times to conduct observations.

> **Flexibility Factor - Assessing Professional Practice**
>
> - Schools and LEAs can choose to provide "formative scores" at the mid-year for Professional Practice. On the Mid-Year Conference form in EEM there is an option to provide a formative score for one or more of the components. A formative score provided at the mid-year does not have to match the score provided at the end-of-year.
> - A one-week window for an announced observation is required, but evaluators may choose to narrow down a timeframe within that week (e.g., "I plan to observe a social skills group"). Because schools and LEAs have some flexibility with scheduling announced observations, support professionals and evaluators should be clear about what is expected at the local level.
> - Written feedback is required after each observation, but pre- and post-observation conferences are optional. Schools and LEAs can choose to implement pre- and/or post-observation conferences depending on what works best for their local needs.

---

## Professional Responsibilities

Support professionals' roles extend beyond collaboration and service delivery. The Rhode Island Model recognizes the additional contributions support professionals make to their school community through the Professional Responsibilities Rubric (Appendix 4).

The Professional Responsibilities Rubric includes seven components that are aligned with local and national standards related to individual support professional disciplines and with the Rhode Island Code of Professional Responsibility.

### Professional Responsibilities Rubric Components

| Domain 1: School Responsibilities and Communication | Domain 2: Professionalism | Domain 3: Professional Growth |
|-----------------------------------------------------|--------------------------|------------------------------|
| **PR1:** Understand and participates in school/district-based initiatives and activities | **PR3:** Acts on the belief that all students can learn and advocates for students' best interests | **PR6:** Engages meaningfully in school and district professional growth opportunities and enhances professional growth by giving and seeking assistance from other educators in order to improve student learning |
| **PR2:** Solicits and maintains records of, and communicates appropriate information about students' behavior, learning needs, and academic progress | **PR4:** Works toward a safe, supportive, collaborative culture by demonstrating respect for everyone, including other educators, students, parents, and other community members in all actions and interactions | **PR7:** Writes and implements a professional growth goal that addresses personal, school, or district needs and aims at improving support professional practice |
| | **PR5:** Acts ethically and with integrity following all school, district, and state policies | |

### Assessing Professional Responsibilities

Evaluators score the seven components using the rubric based on evidence collected during the year. Evaluators can observe all of the components in action but may choose to collect additional evidence through artifact review.

Evaluators should maintain notes that serve as evidence of components seen in action and integrate feedback on this evidence into evaluation conference discussions. If evaluators choose to review artifacts, artifact review should focus on quality rather than quantity. One artifact could be used to demonstrate proficiency on more than one component of the rubric.

> **Flexibility Factor - Professional Responsibilities**
>
> - Schools and LEAs have the flexibility to determine the evidence that will be used for the Professional Responsibilities components. RIDE recommends assessing components in action whenever possible.
> - Schools and LEAs can choose to provide "formative scores" at the mid-year for Professional Responsibilities Rubric. On the Mid-Year Conference form in EEM there is an option to provide a formative score for one or more of the components. A formative score provided at the mid-year does not have to match the score provided at the end-of-year conference.
> - LEAs may choose to have support professionals write Professional Growth Goals in their non-summative years of the cyclical process.

### Professional Growth Goal

All support professionals in their summative evaluation year must create a Professional Growth Goal (PGG) at the beginning of the year. The evaluator will score the goal at the end of the year using PR 7 of the Professional Responsibilities Rubric. This goal must focus the support professional's learning and development throughout the year. More specifically, the Professional Growth Goal should:

- Be informed by school, LEA, or educator data.
- Address a school, LEA, or personal goal.
- Align with the Professional Practice and/or Professional Responsibilities Rubrics.
- Be specific, measurable, and actionable.
- Include specific action steps.
- Identify how goal attainment will be measured.
- Be discussed and finalized during or directly after the Beginning-of-Year Conference.

### Adjusting a Professional Growth Goal Mid-Year

While it is ideal to establish a goal that is ambitious but realistic, the Mid-Year Conference provides a formal opportunity for the support professional and evaluator to review the Professional Growth Goal and make adjustments if necessary. If the goal is achieved before the end of the year or if planned activities are not possible, the support professional and evaluator may decide to revise the Professional Growth Goal.

---

## Measures of Student Learning

Improving student learning is at the center of all our work and measuring specific outcomes that will increase access to learning for students is a critical part of our support professional's evaluation model. The Rhode Island Model measures a support professional's impact on student learning in two ways: Student Learning Objectives (SLOs) and/or Student Outcome Objectives (SOOs). Measures of student learning are included in support professional's evaluations because:

- Support professionals provide services that have a direct impact on access to learning, even if direct instruction is not their primary role.
- Student learning measures, when combined with observations of Professional Practice and evidence of Professional Responsibilities, improve the accuracy of the Final Effectiveness Ratings for support professionals.
- Analyzing student data is a best practice for self-reflection and increased collaboration around improving service delivery and student outcomes.

### Student Learning Objectives and Student Outcome Objectives

Both SLOs and SOOs can be used as a measure of a support professional's impact on student learning, either directly through demonstrated progress toward specific, measureable goals, or through increasing access to learning. An **SLO** is a long-term academic goal set for groups of students. An **SOO** is a long-term goal that is focused on an outcome that increases access to learning or creates conditions that facilitate learning. Both SLOs and SOOs can be set for the school year or an interval of service delivery/instruction appropriate to their assignment (e.g., a single semester). They must be specific and measureable, based on available student information, and aligned with standards, as well as any school and district priorities where applicable. Additionally:

- **The SLO/SOO process respects the diversity of all support professionals' roles.** The best way to measure student outcomes or student access to learning differs from role to role. These objectives present an opportunity for support professionals to be actively involved in deciding how to best measure the outcomes of goals for their specific population of students, while providing a consistent process for all support professionals across the state.
- **SLOs/SOOs focus educator attention where it matters most: on student outcomes.** Both SOOs and SLOs ask support professionals to think strategically about their impact on student learning, whether through direct instruction or increasing access to learning.

### Student Learning/Outcome Objective Decision Tree

This decision tree is used to assist support professionals in determining whether they should set SLOs, SOOs, or a combination of both. The determination of a support professional's student learning options is based upon the specific role. LEAs need to determine what type of student learning measure is most appropriate for the specific positions in their LEA.

[Image: Decision tree flowchart]

**Do you primarily provide instruction to students?**
- **Yes** → Set 2 SLOs
- **No** → Do you primarily provide specialized services or manage a program?
  - **Yes** → Set 2 SOOs
  - **No** → Is your role a combination of providing instruction and providing specialized services and/or managing a program?
    - **Yes** → 1 SOO and 1 SLO
    - **No** → Determine with evaluator if you should set an SOO or an SLO

### The Student Learning/Outcome Process

The process for setting SLOs and SOOs is the same, regardless of whether an educator is setting SLOs, SOOs, or a combination of SLOs/SOOs. Support professionals should, whenever possible, work collaboratively with colleagues to set SLOs/SOOs. The process is meant to foster reflection and conversation about the essential curriculum, strategies, and assessment tools used in schools across the state.

The SLO/SOO process mirrors a support professional's planning, instruction/service delivery, and assessment cycle as seen by the chart below:

[Image: Process diagram with four stages]

**Preparation**
- Review standards, units of study, past service delivery methods, and how they improved access to learning for students
- Review available assessments currently used to assign grades and monitor students' progress
- Determine priority service/s/content
- Review available historical data

**Development**
- Get to know students (collect and analyze baseline data)
- Re-evaluate priority services/content based on student needs
- Draft and submit SLOs/SOOs
- Receive SLO/SOO approval (revise if necessary)

**Instruction/Service Delivery**
- Teach/implement service delivery and monitor student learning/access to learning
- Discuss progress with colleagues and evaluator(s)
- Make adjustments to SLOs/SOOs by mid-year (if necessary)
- Adjust service delivery if students are not progressing as expected
- Collect, analyze, and report on SLO/SOO results

**Reflection**
- Collect, analyze, and report final evidence of student learning/access to learning
- Evaluator and support professional review outcomes
- Reflect on outcomes to improve implementation and practice

### The Anatomy of Student Learning Objectives & Student Outcome Objectives

The SLO and SOO forms are structured to help educators answer three essential questions.

**SLO Form:**
1. What are the most important knowledge/skills I want my students to attain by the end of the interval of instruction?
2. Where are my students now (at the beginning of instruction) with respect to the objective?
3. Based on what I know about my students, where do I expect them to be by the end of the interval of instruction and how will they demonstrate their knowledge/skills?

**SOO Form:**
1. What is the most important outcome that will enable students to have better access to education through my services?
2. Where are my students now with respect to this objective?
3. Based on what I know about them, where do I expect my students to be by the end of the interval of service? How will I measure this change?

#### Anatomy of a Student Learning Objective (Form)

**Title** – A short name for the SLO

**Content Area** – The content area(s) to which this SLO applies

**Grade Level** – The grade level(s) of the students

**Students** – The number and grade/class of students to whom this SLO applies

**Interval of Instruction** – The length of the course (e.g., year, semester, quarter)

| Main Criteria | Element | Description |
|---------------|---------|-------------|
| **Essential Question: What are the most important knowledge/skills I want my students to attain by the end of the interval of instruction? Priority of Content** | **Objective Statement** | • Identifies the priority content and learning that is expected during the interval of instruction<br>• Should be broad enough that it captures the major content of an extended instructional period, but focused enough that it can be measured<br>• If attained, positions students to be ready for the next level of work in this content area |
| | **Rationale** | • Provides a data-driven and/or curriculum-based explanation for the focus of the Student Learning Objective |
| | **Aligned Standards** | • Specifies the standards (e.g., CCSS, Rhode Island GSEs, GLEs, or other state or national standards) to which this objective is aligned |
| **Essential Question: Where are my students now (at the beginning of instruction) with respect to the objective?** | **Baseline Data/ Information** | • Describes students' baseline knowledge, including the source(s) of data/ information and its relation to the overall course objectives |
| **Essential Question: Based on what I know about my students, where do I expect them to be by the end of the interval of service and how will they demonstrate their knowledge/skills? Rigor of Target** | **Target(s)** | • Describes where the teacher/support professional expects all students to be at the end of the interval of instruction<br>• Should be measurable and rigorous, yet attainable for the interval of instruction<br>• In most cases, should be tiered to reflect students' differing baselines |
| | **Rationale for Target(s)** | • Explains the way in which the target was determined, including the data source (e.g., benchmark assessment, historical data for the students in the course, historical data from past students) and evidence that indicate the target is both rigorous and attainable for all students<br>• Should be provided for each target and/or tier |
| **Quality of Evidence** | **Evidence Source(s)** | • Describes how student learning will be assessed and why the assessment(s) is appropriate for measuring the objective<br>• Describes how the measure of student learning will be administered (e.g., once or multiple times; during class or during a designated testing window; by the classroom teacher or someone else)<br>• Describes how the evidence will be collected and scored (e.g., scored by the classroom teacher individually or by a team of teachers; scored once or a percentage double-scored) |

#### Anatomy of a Student Outcome Objective (Form)

**Title** – A short name for the SOO

**Content Area** – The service area(s) to which this SOO applies

**Grade Level** – The grade level(s) of the students

**Students** – The number of students to whom this SOO applies

**Interval of Service** – The interval of service defines the period to which the SOO applies. It should mirror the length of time in which the educator is actively working with students, typically one academic year, one semester or a shorter timeframe, as justified by the duration of the service(s) being delivered.

| Main Criteria | Element | Description |
|---------------|---------|-------------|
| **Essential Question: What is the most important outcome that will enable students to have better access to education through your services? Priority of Content** | **Objective Statement** | • Describes the specific outcome that the support professional is working to achieve<br>• Should be specific enough to clarify the focus of the SOO |
| | **Rationale** | • Provides a data-driven explanation for the focus of the SOO and indicates if it is aligned with a school or district priority |
| **Essential Question: Where are my students now with respect to the objective?** | **Baseline Data / Information** | • Supports the overall reasoning for the student outcome objective<br>• Could include survey data, statistics, participation rates, or references to historical trends or observations |
| **Essential Questions: Based on what I know about my students, where do I expect them to be by the end of the interval of service? How will I measure this? Rigor of Target** | **Target(s)** | • Describes where it is expected for groups of students or the school community as a whole to be at the end of the interval of service<br>• Should be measurable and rigorous, yet attainable |
| | **Rationale for Target(s)** | • Explains the way in which the target was determined, including the baseline information sources and why the target is appropriate for the group of students or the school community<br>• Explains the way in which the target was determined, including the data source (e.g., benchmark assessment, trend data, or historical data from past students) and evidence that indicate the target is both rigorous and attainable for all students<br>• Rationale should be provided for each target and/or tier |
| **Quality of Evidence** | **Evidence Source(s)** | • Describes how the objective will be measured and why the evidence source(s) is appropriate for measuring the objective (e.g. logs, scoring guides, screening procedures, surveys)<br>• Describes how the measure of the student outcome will be collected or administered (e.g., once or multiple times; during class time or during a designated testing window; by the support professional or someone else)<br>• Describes how the evidence will be analyzed and/or scored (e.g., scored by the support professional individually or by a team of support professionals; scored once or a percentage double-scored) |
| | **Strategies** | • Describes the method, strategies, or plan that will be used to achieve your goal |

---

## New Student Learning Flexibilities

Beginning with the 2019-20 school year, LEAs will be able to implement new student learning flexibilities: The SLO Flex and the SOO Flex. For both SLOs and SOOs, support professionals now have the option to employ flexible processes and procedures in measuring their impact on student learning, either directly through demonstrated progress toward specific, measureable goals, or through increasing access to learning.

The new flexibilities are the result of feedback from the field – both educators and evaluators have wanted the option to tailor SLOs/SOOs in ways that align with specific school goals and/or local context. For example, support professionals now have the option of focusing on a smaller subset of students instead of including everyone on their caseload. Additionally, they could set several shorter cycle goals that support an interval of service versus setting one year-long goal that may not prove practical given the focus. Finally, it is perfectly allowable to revise a target based on data/evidence from a shorter cycle of instruction. In this case, the new data-driven target would support the next cycle of instruction.

As with any flexibility offered in the evaluation system, support professionals must first seek leadership approval before taking advantage of any of the following flexibilities:

**SLO Flex**
- Flexible processes and procedures using the SLO original template:
  - All students or a targeted subset
  - One or more content standards
  - Year-long or shorter cycles of instruction
  - Targets may be adjusted based on data/evidence from shorter cycles of instruction

**SOO Flex**
- Flexible processes and procedures using the SOO original template:
  - All students or a targeted subset
  - Year-long or shorter cycles of instructional support
  - Strategies may be adjusted based on data/evidence from shorter cycles of instruction
  - Targets may be adjusted based on data/evidence from shorter cycles of instruction

Please know that whether or not the support professional – with approval from their evaluator – takes advantage of these new flexibilities, student learning continues to comprise 30% of the Final Effectiveness Rating.

---

## Number and Scope of Student Learning/Outcome Objectives

Support professionals and evaluators should work together to determine how many SLOs/SOOs are appropriate for their specific role. The minimum number of SLOs/SOOs a support professional may set is two. Support professionals should discuss their rationale for selecting a particular area of focus with their evaluators at the beginning of the school year.

### Students

A support professional's SLO/SOO may include all of the students in the school or focus on subgroups of students (e.g., caseload, specific grade level, course). An individual SLO/SOO that is focused on a subgroup must include all students in that subgroup with which the objective is aligned if SLO/SOO Flex is not in effect. An example for a school psychologist is below:

[Image: Table showing SOO 1: Stress Management with Sections A, B, C and SOO 2: Bullying Prevention with grades 6, 7, 8]

SOO 1 includes all students in all three sections of the stress management group

SOO 2 includes all students in all 3 grades

Keep in mind that percentages or particular groups of students (e.g., students with IEPs) may not be excluded. Support professionals may not include absenteeism clauses into SLOs/SOOs (e.g. "for students who are present 80% of the time) because these potentially exclude students. However, an evaluator can take extreme absenteeism into account when scoring the SLO/SOO.

Setting tiered targets according to students' starting points is recommended because students may begin at varying levels of preparedness. However, the expectation is that all students should make gains regardless of where they start. For example, students who begin below expectations may have a target of making substantial progress toward objectives by the end of the interval of service delivery, reducing the gap between their current and expected performance, while students who begin at a higher level may have a target of meeting or exceeding expectations by the end of the service delivery period.

### Baseline Data/Information

Data is information, and educators collect information from students every day in order to help them plan effectively, adjust instruction/service delivery, monitor progress, and assess student performance. In order to set appropriate long-term goals for students, support professionals must understand where their students are at the beginning of instruction/service delivery. There are many ways that support professionals understand their students' starting points at the beginning of the year. When determining which baseline data are available and how they might be used, consider the following:

- Student data from prior years in many cases can be used to inform the support professional's understanding of students' starting points.
- Data collected at multiple points over time (e.g. logs, survey data, immunization records) may be useful because they can show trends.
- Baseline data from a pre-assessment may be helpful when it is important to understand students' skill or knowledge level at the beginning of the course/service delivery. This assessment could be a locally-created or commercial assessment and focus on either the current or previous grade's standards and content.

Baseline data/information can be used in two ways for SLOs/SOOs; it can inform the Objective Statement and contribute to setting Targets. In all scenarios baseline data/information is a must; however, **a pre-test/post-test model is not required and, in some cases, might be inappropriate.**

The function of the baseline assessment is to provide information about where students are starting in order to set appropriate targets. This does not mean that it is necessary to pinpoint projected student growth, since some targets may focus on reaching a specific level of proficiency. Support professionals should gather information that helps them understand where their students are in relation to their preparedness to access the material of the class/services.

### Rigor of Target

When setting the target(s) for an SLO/SOO, the support professional should start by considering where it is expected for groups of students or the school community as a whole to be at the end of the interval of instruction or the interval of service (objective statement) based on where the students are with respect to the objective statement (baseline data).

Not all students begin with the same level of preparedness. Therefore, targets may be tiered to reflect differentiated expectations for learning/outcomes.

Setting tiered targets based on students' prerequisite knowledge and skills helps to ensure that the targets are rigorous and attainable for all students. Students entering a course or grade level with high proficiency or robust prerequisite skills will need to be challenged by a higher target. For students entering a course or grade level with lower proficiency or lacking prerequisite skills, a more modest target may be appropriate in order to ensure that it is reasonably attainable in the interval of instruction/service.

That said, the intent of tiered targets is not to calcify achievement gaps. The needs for fairness and appropriateness should be balanced by the need to challenge lower-achieving students to catch up to their peers. Additionally, while students in lower tiers may have a lower absolute target, reaching it may require them to make more progress than students with higher targets, resulting in a closing or narrowing of the achievement gap(s).

The following graphic shows one example of how to tier targets for an SLO based on students' preparedness for the content:

[Image: Circular diagram showing "Where do students need to be?" and "Where are they now?" with three tiers of students]

**Tier 1 Target**
Some students are entering the course without the necessary prerequisite knowledge or skills.

**Tier 2 Target**
Some students are entering the course with the necessary prerequisite knowledge or skills.

**Tier 3 Target**
Some students are entering the course with prerequisite knowledge or skills that exceed what is expected or required.

### Quality of Evidence

High-quality evidence sources are essential for accurately measuring students' learning. **In Rhode Island, a variety of evidence sources may be used for SLOs/SOOs, including performance tasks, extended writing, research papers, projects, portfolios, unit assessments, final assessments, behavior charts, survey data, attendance records, etc.** A combination of evidence sources may also be used. Evidence sources may be created by individual support professionals, teams, district leaders, or purchased from a commercial vendor. However, evaluators must review all assessments.

Selecting the right evidence source for an SLO is about finding the best assessment for the purpose. In order to make this determination, the question to ask is, "Is this evidence source aligned to what is being measured?" Alignment of evidence source refers to:

- **Content** (e.g., The SLO focuses on reading informational text and the evidence source focuses on informational text)
- **Coverage** (e.g., The SLO includes five standards and all five of those standards are addressed by the evidence source)
- **Complexity** (e.g., The SLO addresses a variety of DOK levels and the evidence source includes items/tasks aligned with those DOK levels).

The evidence source for an SOO may include:

- Data on the outcome itself (e.g., truancy rates, survey data on 11th grade students' attitudes toward drinking and driving).
- Indicators related to the outcome (e.g., participation in school social events and clubs as an indicator of student engagement).
- Documentation of the action taken on the part of the support professional to move a student, group of students, or the school toward the outcome (e.g., creating a bullying prevention program for students).

An assessment may be high-quality for a particular purpose, but if it is not aligned to the Objective Statement of the SLO/SOO, it is not the best choice. Additionally, the use of a single evidence source can be problematic if it does not capture the full breadth of the Objective Statement. Consider the following examples:

- **The SLO Objective Statement says** that students will improve their reading accuracy, fluency, and comprehension of literary and informational text, and their ability to convey information about what they've read. One assessment might be used to measure reading accuracy, fluency, and some comprehension of both literary and information text. Another assessment might be used to measure deeper reading comprehension and their ability to convey information about what they've read.

- **The SOO Objective Statement says** that the overall health, wellness, and safety of students will improve. One evidence source might be used to track immunization records. A second evidence source may track the vision screening results and follow up. A third assessment may be used to assess the effectiveness of professional development sessions.

Other considerations for determining the quality of an evidence source include format, item type, and administration and scoring procedures. In most cases, the evidence source(s) should be as authentic as possible without being impractical to administer and score. The following table includes further guidance on selecting high-quality assessments. These Assessment Quality Descriptors represent some of the most important aspects of an assessment to consider. Some of the criteria are inherent to the assessment (e.g., the purpose), while others relate to an educator's use of the assessment (e.g., the scoring process).

### Assessment Quality Rubric for SLOs:

| Quality Level | Criteria |
|--------------|----------|
| **High Quality** | • Assessment is **aligned** with its intended use.<br>• Assessment **measures** what is intended.<br>• Items represent a **variety** of DOK levels.<br>• Assessment includes a **sufficient** number of items to reliably assess content.<br>• Assessment includes some higher level DOK constructed response items at least one very challenging item.<br>• Assessment is **grade level appropriate and aligned** to the curriculum.<br>• Scoring is **objective** (includes scoring guides and benchmark work), and uses a **collaborative** scoring process. |
| **Moderate Quality** | • Assessment is **loosely aligned** to its intended use.<br>• Assessment **mostly measures** what is intended.<br>• Items represent **more than one** level of DOK.<br>• Assessment includes a **sufficient** number of items to reliably assess most content<br>• Assessment is **grade level appropriate**.<br>• Scoring may include **scoring guides** to decrease subjectivity, and/or may include **collaborative** scoring. |
| **Low Quality** | • Assessment is **not aligned** to its intended use.<br>• Assessment **does not measure** what is intended.<br>• Items represent **only one** level of DOK.<br>• Assessment includes an **insufficient** number of items to reliably assess most content<br>• Assessment is **not grade level appropriate**.<br>• Scoring is **open to subjectivity**, and/or **not collaboratively** scored. |

---

## Approving Student Learning/Outcome Objectives

In order for an SLO/SOO to be approved, it must be rated as acceptable on three criteria:

1. **Priority of Content**
2. **Rigor of Target(s)**
3. **Quality of Evidence**

## Reviewing Student Learning/Outcome Objectives at the Mid-Year Conference

Whether using the original SLO/SOO or the SLO/SOO Flex options, the Mid-Year Conference offers an opportunity for support professionals to review and discuss their students' learning progress with their evaluators. Support professionals and evaluators should work together to ensure students' learning needs are effectively addressed through instructional practice and supports. If students are not progressing as expected, the support professional and evaluator should collaborate to revise the supports and interventions in place to help accelerate student progress.

If at the Mid-Year Conference it becomes clear that an SLO/SOO is no longer appropriate, it may be revised. Revisions should be rare with the original SLO/SOO, but adjustments may be made if:

- The schedule or assignment has changed significantly.
- Class or caseload compositions have changed significantly.
- New, higher-quality sources of evidence are available.
- Based on new information gathered since they were set, objectives fail to address the most important learning or access to learning challenges in the classroom/school.

**NOTE:** There may be extenuating circumstances that do not fit these four categories in which the evaluator must use professional judgment. Additionally, when a support professional is using the SLO/SOO Flex options, they have the "built-in" option of adjusting targets and/or strategies based on student data; in these cases, the circumstance need not be extenuating when exercising the option of revising student learning targets and/or strategies. For example, when changing targets based on data from instruction, support professionals should consult with the evaluator as part of ongoing data discussions. In most cases, these discussions include not only a rationale for the change based on the data, but the instructional strategies that will be continued and/or adjusted based on the needs of students.

### Multilingual Learner (MLL) / English Learner (EL) Students

Like general educators, support professionals should incorporate Multilingual Learners (MLLs) and English Learners (ELs) in their SLOs/SOOs. Support Professionals may set differentiated targets to ensure that all students are meeting a rigorous, yet attainable, target. In some cases, evidence may need to be differentiated for MLL/EL students to account for how they currently use language to demonstrate content skills and knowledge. Where applicable, support professionals should ensure their content targets for MLL/EL students are aligned to both grade level state adopted content standards and the WIDA English Language Development (ELD) standards.

It is useful to know that in WIDA's Guiding Principles of Language Development, language is learned within context, as one learns content. For more information regarding language and content objectives for MLLs/ELs, please visit Essential Actions: A Handbook for Implementing WIDA's Framework for English Language Development Standards.

We encourage all educators and administrators to visit the Multilingual Learners (MLLs)/ English Learners (ELs) page on our RIDE website for current information and resources.

### Students with Disabilities

Special educators provide specially designed instruction in a variety of settings and delivery models to meet the diverse needs of their students. Because of the unique needs of the students, special educators' impact on their students' learning may be measured through the use of SLOs and/or Student Outcome Objectives (SOOs). Please use the decision tree on Page 25 to determine when it makes sense to set SLOs or a combination of an SLO/SOO.

SLOs for students with disabilities should be based on Common Core State Standards or other appropriate content standards, historical performance data, and other academic information. Educators working to support students' skills across grade levels in core content can refer to the interactive CCSS coherence map for math skills, the K-5 (pp. 11-17) and 6-12 (pp. 36-40) standards in ELA, the Next Generation Science Standards (NGSS) resources for science skills and RIDE's graduation proficiencies and performance indicators for History and Social Studies. Those educators who instruct students who participate in alternative assessments should refer to the Tested Essential Elements page on the RIDE website for information that can be used to inform instructional planning and goal-setting.

**Although there may be overlap in the content, assessments, or evidence used, Individualized Education Program (IEP) goals cannot be used as SLOs or SOOs. SLOs include a complete roster of students, whereas IEP goals are independently crafted for each student.** IEPs can inform a teacher's, support professional's, or an instructional team's SLO/SOO by providing data to inform Baseline Data/Information and Targets. IEP goals, assessments, and other evidence may inform the SLOs/SOOs on specific content areas.

SOOs for students with disabilities are long-term goals set by special educators that are focused on outcomes that increase access to learning. The focus of an SOO is to foster academic success for students. SOOs could be set for the full academic year or the length of time services are provided. An SOO must be specific and measurable, and should be aligned to standards or school or LEA priorities, when applicable. For example, SEL Standards and Indicators in the areas of functional skills such as self-management, responsible decision making, and relationship skills which are necessary for students' access to the general education curriculum may be used for SOOs because they focus on outcomes that increase access to learning.

Special educators may tier their SLO or SOO targets based on student baseline data/information to ensure the targets are rigorous, yet attainable for all students included within the SOO. There is no maximum number of tiers an educator can create for a set of students. Some educators with smaller caseloads may write SLOs/SOOs in which each student has his or her own target based on individualized starting points and rate of progress. This data may be found within the IEP. Special educators, support professionals, and general educators must collaborate when setting targets for students with disabilities.

---

## Scoring Individual Student Learning/Outcome Objectives

The process for scoring individual SLOs/SOOs begins with a review of the available evidence submitted by the support professional, including a summary of the results. Evaluators will score each individual SLO/SOO as **Exceeded, Met, Nearly Met, or Not Met**.

### Additional Student Learning/Outcome Objective Scoring Guidance

To help further clarify the definitions of Exceeded, Met, Nearly Met, and Not Met, RIDE has developed the following scoring guidelines that LEAs can choose to adopt.

**Not Met**
- This category applies when the results do not fit the description of what it means to have "Nearly Met." If a substantial proportion of students did not meet the target(s), the SLO/SOO was not met. This category also applies when results are missing, incomplete, or unreliable.
- **<70% of students met their target**

**Nearly Met**
- This category applies when many students met the target(s), but the target(s) was missed by more than a few points, a few percentage points, or a few students. This category should be selected when it is clear that students fell short of the level of attainment established by the target(s).
- **70-89% of students met their target**

**Met**
- This category applies when all or almost all students met the target(s). Results within a few points, a few percentage points, or a few students on either side of the target(s) should be considered "Met." The bar for this category should be high and it should only be selected when it is clear that the students met the overall level of attainment established by the target(s).
- **At least 90% of students met their target**

**Exceeded**
- This category applies when all or almost all students met the target(s) and many students exceeded the target(s). For example, exceeding the target(s) by a few points, a few percentage points, or a few students would not qualify an SLO/SOO for this category. This category should only be selected when a substantial number of students surpassed the overall level of attainment established by the target(s).
- **At least 90% of students met their target AND**
- **25% of students exceeded their target**

**NOTE:** The additional SLO/SOO scoring guidance above does not eclipse local LEA policy. LEAs have the flexibility to adopt the additional SLO/SOO scoring guidance, create their own guidance, or choose to continue to use the Exceeded, Met, Nearly Met, and Not Met descriptions exclusively. For example, LEAs may want to create specific guidance for scoring SLOs that represent a small number of students.

---

## Student Learning/Outcome Objective Scoring Process Map

The SLO/SOO Scoring Process Map below outlines the specific steps an evaluator should take to determine if individual SLOs/SOOs are Exceeded, Met, Nearly Met, or Not Met.

[Image: Decision tree flowchart]

**How many students reached their targets?**
↓
**Did all or almost all students reach their targets?**
- **Yes** → **Did a substantial amount of students greatly exceed their targets?**
  - **Yes** → **Exceeded**
  - **No** → **Met**
- **No** → **Were most students close to their targets?**
  - **Yes** → **Nearly Met**
  - **No** → **Not Met**

---

## Calculating a Final Effectiveness Rating

The Final Effectiveness Rating is determined by combining the points from each of the four criteria of the model. The total number of points possible is 400 with Professional Practice: Collaboration weighing 25%, Professional Practice: Service Delivery weighing 25%, Professional Responsibilities weighing 20% and Student Learning weighing 30%.

### Components of a Final Effectiveness Rating in Points

[Image: Pie chart showing points breakdown]

- **Professional Practice: Collaboration** 25% | 100 points
- **Professional Practice: Service Delivery** 25% | 100 points
- **Professional Responsibilities** 20% | 80 points
- **Student Learning** 30% | 120 points

The overall point value is then converted to one of four Final Effectiveness Ratings:

- **Highly Effective (H)**
- **Effective (E)**
- **Developing (D)**
- **Ineffective (I)**

The following section explains how to calculate the final effectiveness rating.

---

## Step 1 – Calculate a Professional Practice: Collaboration score.

- The evaluator refers to all available data related to the support professional's performance over the course of the year, including any artifacts, observation of practice notes, and written feedback they have provided. The evaluator reviews performance descriptors for each Professional Practice: Collaboration component and selects the one that best describes the support professional's performance for the year. If the support professional's performance does not neatly fit descriptors at a single performance level, the evaluator will choose the level that is the closest overall match based on the preponderance of evidence.

- The scores for each of the four components of Professional Practice: Collaboration will be added together to get a component sum. The chart below provides an example of scores for each component and the calculation of the component sum.

| Component | Score |
|-----------|-------|
| 1a | 4 |
| 1b | 3 |
| 1c | 3 |
| 1d | 3 |
| **COMPONENT SUM** | **13** |

- The total number of weighted points is calculated by dividing the component sum by the number of components (4) and then multiplying by the measure's weight times 100 (25% x 100 = 25). The lookup table below shows the conversion between the component sum and weighted points. In the example above, the support professional would earn 81 weighted points for Professional Practice: Collaboration.

### Collaboration: 25% of 400 points, 100 points total

| Component Sum | Points | Weighted Points |
|---------------|--------|-----------------|
| 16 | 4.00 | 100 |
| 15 | 3.75 | 94 |
| 14 | 3.50 | 88 |
| 13 | 3.25 | **81** |
| 12 | 3.00 | 75 |
| 11 | 2.75 | 69 |
| 10 | 2.50 | 63 |
| 9 | 2.25 | 56 |
| 8 | 2.00 | 50 |
| 7 | 1.75 | 44 |
| 6 | 1.50 | 38 |
| 5 | 1.25 | 31 |
| 4 | 1.00 | 25 |

---

## Step 2 – Calculate a Professional Practice: Service Delivery score.

- The evaluator refers to all available data related to the support professional's performance over the course of the year, including any artifacts, observation of practice notes, and written feedback they have provided. The evaluator reviews performance descriptors for each Professional Practice: Service Delivery component and selects the level which best describes the support professional's performance for the year. If the support professional's performance does not neatly fit descriptors at a single performance level, the evaluator will choose the level that is the closest overall match based on the preponderance of evidence.

- The scores for each of the four components of Professional Practice: Service Delivery will be added together to get a component sum. The chart below provides an example of scores for each component and the calculation of the component sum.

| Component | Score |
|-----------|-------|
| 2a | 3 |
| 2b | 3 |
| 2c | 3 |
| 2d | 2 |
| **COMPONENT SUM** | **11** |

- The total number of weighted points is calculated by dividing the component sum by the number of components (4) and then multiplying by the measure's weight times 100 (25% x 100 = 25). The lookup table below shows the conversion between the component sum and weighted points. In the example above, the support professional would earn 69 weighted points for Professional Practice: Collaboration.

### Service Delivery: 25% of 400 points, 100 points total

| Component Sum | Points | Weighted Points |
|---------------|--------|-----------------|
| 16 | 4 | 100 |
| 15 | 3.75 | 94 |
| 14 | 3.5 | 88 |
| 13 | 3.25 | 81 |
| 12 | 3 | 75 |
| 11 | 2.75 | **69** |
| 10 | 2.5 | 63 |
| 9 | 2.25 | 56 |
| 8 | 2 | 50 |
| 7 | 1.75 | 44 |
| 6 | 1.5 | 38 |
| 5 | 1.25 | 31 |
| 4 | 1 | 25 |

---

## Step 3 – Calculate a Professional Responsibilities Rating.

- Evaluators review all available data related to the support professional's performance over the course of the year. Evaluators review performance descriptors for each professional responsibilities component and select the level for each component which best describes the support professional's performance for the year.

- The scores for each component will be added together to get a total Professional Responsibilities Rubric score. The component sum will always be between 7 and 28 points.

- A lookup table is used to determine the number of weighted points. The total number of weighted points is calculated by dividing the component sum by the number of components (7) and then multiplying by the measure's weight times (20% x 100 = 20). For example, a support professional with a component sum of 23 would earn 66 weighted points for Professional Responsibilities.

### Professional Responsibilities: 20% of 400 points, 80 points total

| Component Sum | Points | Weighted Points |
|---------------|--------|-----------------|
| 28 | 4.00 | 80 |
| 27 | 3.86 | 77 |
| 26 | 3.71 | 74 |
| 25 | 3.57 | 71 |
| 24 | 3.43 | 69 |
| 23 | 3.29 | **66** |
| 22 | 3.14 | 63 |
| 21 | 3.00 | 60 |
| 20 | 2.86 | 57 |
| 19 | 2.71 | 54 |
| 18 | 2.57 | 51 |
| 17 | 2.43 | 49 |
| 16 | 2.29 | 46 |
| 15 | 2.14 | 43 |
| 14 | 2.00 | 40 |
| 13 | 1.86 | 37 |
| 12 | 1.71 | 34 |
| 11 | 1.57 | 31 |
| 10 | 1.43 | 29 |
| 9 | 1.29 | 26 |
| 8 | 1.14 | 23 |
| 7 | 1.00 | 20 |

---

## Step 4 – Calculate a Student Learning Score.

- Evaluators score each individual SLO/SOO as **Exceeded (4), Met (3), Nearly Met (2), or Did Not Meet (1)**. The SLO/SOO Scoring Process Map on page 31 outlines the specific steps an evaluator should take to determine SLO/SOO scores. Once individual SLOs/SOOs are scored, the number of points earned (1-4) on each SLO/SOO is added together to calculate a component sum. The component sum is then divided by the number of SLOs/SOOs and multiplied by the weight of 30 to get a total number of points. For example, two ratings of Met would receive 90 weighted points.

### Student Learning – 2 SLOs, 2 SOOs or 1 SLO and SOO: 30% of 400 points, 120 points total

| SLO/SOO Combination | Component Sum | Points | Weighted Points |
|-------------------|---------------|--------|-----------------|
| Exceeded (4), Exceeded (4) | 8 | 4.00 | 120 |
| Exceeded (4), Met (3) | 7 | 3.50 | 105 |
| Met (3), Met (3) | 6 | 3.00 | **90** |
| Exceeded (4), Nearly Met (2) | 6 | 3.00 | 90 |
| Met (3), Nearly Met (2) | 5 | 2.50 | 75 |
| Exceeded (4), Not Met (1) | 5 | 2.50 | 75 |
| Nearly Met (2), Nearly Met (2) | 4 | 2.00 | 60 |
| Met (3), Not Met (1) | 4 | 2.00 | 60 |
| Nearly Met (2), Not Met (1) | 3 | 1.50 | 45 |
| Not Met (1), Not Met (1) | 2 | 1.00 | 30 |

---

## Step 5 – Calculate the total number of points earned.

The total number of points from Professional Practice: Collaboration, Professional Practice: Service Delivery, Professional Responsibilities and Student Learning is added together to determine a sum of the total number of points out of a possible 400 points.

| Measures | Weighted Points |
|----------|-----------------|
| Professional Practice: Collaboration | 81 |
| Professional Practice: Service Delivery | 69 |
| Professional Responsibilities | 66 |
| Student Learning | 90 |
| **Total** | **306** |

---

## Step 6 – Determine the Final Effectiveness Rating.

The final effectiveness rating is assigned using the lookup table below to determine one of four possible ratings.

### Final Effectiveness Scoring Bands

| Rating | Points |
|--------|--------|
| Highly Effective | 360-400 |
| Effective | **295-359** |
| Developing | 200-294 |
| Ineffective | 100-199 |

In the example above, with a total of 306 points, the support professional would receive an **Effective** rating.

---

## Appendix 1: Lookup Tables to Calculate the Final Effectiveness Rating

### Collaboration: 25% of 400 points, 100 points total

| Component Sum | Points | Weighted Points |
|---------------|--------|-----------------|
| 16 | 4.00 | 100 |
| 15 | 3.75 | 94 |
| 14 | 3.50 | 88 |
| 13 | 3.25 | 81 |
| 12 | 3.00 | 75 |
| 11 | 2.75 | 69 |
| 10 | 2.50 | 63 |
| 9 | 2.25 | 56 |
| 8 | 2.00 | 50 |
| 7 | 1.75 | 44 |
| 6 | 1.50 | 38 |
| 5 | 1.25 | 31 |
| 4 | 1.00 | 25 |

### Service Delivery: 25% of 400 points, 100 points total

| Component Sum | Points | Weighted Points |
|---------------|--------|-----------------|
| 16 | 4.00 | 100 |
| 15 | 3.75 | 94 |
| 14 | 3.50 | 88 |
| 13 | 3.25 | 81 |
| 12 | 3.00 | 75 |
| 11 | 2.75 | 69 |
| 10 | 2.50 | 63 |
| 9 | 2.25 | 56 |
| 8 | 2.00 | 50 |
| 7 | 1.75 | 44 |
| 6 | 1.50 | 38 |
| 5 | 1.25 | 31 |
| 4 | 1.00 | 25 |

### Student Learning: 30% of 400 points, 120 points total

| SLO/SOO Combination | Points | Weighted Points |
|-------------------|--------|-----------------|
| Exceeded (4) | 4.0 | 120 |
| Exceeded (4), Exceeded (4) | 4.0 | 120 |
| Exceeded (4), Met (3) | 3.5 | 105 |
| Met (3), Met (3) | 3.0 | 90 |
| Exceeded (4), Nearly Met (2) | 3.0 | 90 |
| Met (3), Nearly Met (2) | 2.5 | 75 |
| Exceeded (4), Not Met (1) | 2.5 | 75 |
| Nearly Met (2), Nearly Met (2) | 2.0 | 60 |
| Met (3), Not Met (1) | 2.0 | 60 |
| Nearly Met (2), Not Met (1) | 1.5 | 45 |
| Not Met (1), Not Met (1) | 1.0 | 30 |

### Professional Responsibilities: 20% of 400 points, 80 points total

| Component Sum | Points | Weighted Points |
|---------------|--------|-----------------|
| 28 | 4.00 | 80 |
| 27 | 3.86 | 77 |
| 26 | 3.71 | 74 |
| 25 | 3.57 | 71 |
| 24 | 3.43 | 69 |
| 23 | 3.29 | 66 |
| 22 | 3.14 | 63 |
| 21 | 3.00 | 60 |
| 20 | 2.86 | 57 |
| 19 | 2.71 | 54 |
| 18 | 2.57 | 51 |
| 17 | 2.43 | 49 |
| 16 | 2.29 | 46 |
| 15 | 2.14 | 43 |
| 14 | 2.00 | 40 |
| 13 | 1.86 | 37 |
| 12 | 1.71 | 34 |
| 11 | 1.57 | 31 |
| 10 | 1.43 | 29 |
| 9 | 1.29 | 26 |
| 8 | 1.14 | 23 |
| 7 | 1.00 | 20 |

### Final Effectiveness Rating Scoring Bands

| Rating | Points |
|--------|--------|
| Highly Effective | 360-400 |
| Effective | 295-359 |
| Developing | 200-294 |
| Ineffective | 100-199 |

---

## Appendix 2: Student Learning Lookup Tables

### Student Learning – 2 SLOs/SOOs: 30% of 400 points, 120 points total

| SLO/SOO Combination | Component Sum | Points | Weighted Points |
|-------------------|---------------|--------|-----------------|
| Exceeded (4), Exceeded (4) | 8 | 4.00 | 120 |
| Exceeded (4), Met (3) | 7 | 3.50 | 105 |
| Met (3), Met (3) | 6 | 3.00 | 90 |
| Exceeded (4), Nearly Met (2) | 6 | 3.00 | 90 |
| Met (3), Nearly Met (2) | 5 | 2.50 | 75 |
| Exceeded (4), Not Met (1) | 5 | 2.50 | 75 |
| Nearly Met (2), Nearly Met (2) | 4 | 2.00 | 60 |
| Met (3), Not Met (1) | 4 | 2.00 | 60 |
| Nearly Met (2), Not Met (1) | 3 | 1.50 | 45 |
| Not Met (1), Not Met (1) | 2 | 1.00 | 30 |

### Student Learning – 3 SLOs/SOOs: 30% of 400 points, 120 points total

| SLO/SOO Combination | Component Sum | Points | Weighted Points |
|-------------------|---------------|--------|-----------------|
| Exceeded (4), Exceeded (4), Exceeded (4) | 12 | 4.00 | 120 |
| Exceeded (4), Exceeded (4), Met (3) | 11 | 3.67 | 110 |
| Exceeded (4), Met (3), Met (3) | 10 | 3.33 | 100 |
| Exceeded (4), Exceeded (4), Nearly Met (2) | 10 | 3.33 | 100 |
| Met (3), Met (3), Met (3) | 9 | 3.00 | 90 |
| Exceeded (4), Met (3), Nearly Met (2) | 9 | 3.00 | 90 |
| Exceeded (4), Exceeded (4), Not Met (1) | 9 | 3.00 | 90 |
| Met (3), Met (3), Nearly Met (2) | 8 | 2.67 | 80 |
| Exceeded (4), Met (3), Not Met (1) | 8 | 2.67 | 80 |
| Exceeded (4), Nearly Met (2), Nearly Met (2) | 8 | 2.67 | 80 |
| Met (3), Met (3), Not Met (1) | 7 | 2.33 | 70 |
| Met (3), Nearly Met (2), Nearly Met (2) | 7 | 2.33 | 70 |
| Exceeded (4), Nearly Met (2), Not Met (1) | 7 | 2.33 | 70 |
| Met (3), Nearly Met (2), Not Met (1) | 6 | 2.00 | 60 |
| Nearly Met (2), Nearly Met (2), Nearly Met (2) | 6 | 2.00 | 60 |
| Exceeded (4), Not Met (1), Not Met (1) | 6 | 2.00 | 60 |
| Nearly Met (2), Nearly Met (2), Not Met (1) | 5 | 1.67 | 50 |
| Met (3), Not Met (1), Not Met (1) | 4 | 1.67 | 50 |
| Nearly Met (2), Not Met (1), Not Met (1) | 4 | 1.33 | 40 |
| Not Met (1), Not Met (1), Not Met (1) | 3 | 1.00 | 30 |

### Student Learning – 4 SLOs: 30% of 400 points, 120 points total

| SLO/SOO Combination | Component Sum | Points | Weighted Points |
|-------------------|---------------|--------|-----------------|
| Exceeded (4), Exceeded (4), Exceeded (4), Exceeded (4) | 16 | 4.00 | 120 |
| Exceeded (4), Exceeded (4), Exceeded (4), Met (3) | 15 | 3.75 | 113 |
| Exceeded (4), Exceeded (4), Exceeded (4), Nearly Met (2) | 14 | 3.50 | 105 |
| Exceeded (4), Exceeded (4), Met (3), Met (3) | 14 | 3.50 | 105 |
| Exceeded (4), Exceeded (4), Exceeded(4), Not Met (1) | 13 | 3.25 | 98 |
| Exceeded (4), Exceeded (4), Met (3), Nearly Met (2) | 13 | 3.25 | 98 |
| Exceeded (4), Met (3), Met (3), Met (3) | 13 | 3.25 | 98 |
| Exceeded (4), Exceeded (4), Met (3), Not Met (1) | 12 | 3.00 | 90 |
| Exceeded (4), Exceeded (4), Nearly Met (2), Nearly Met (2) | 12 | 3.00 | 90 |
| Exceeded (4), Met (3), Met (3), Nearly Met (2) | 12 | 3.00 | 90 |
| Met (3), Met (3), Met (3), Met (3) | 12 | 3.00 | 90 |
| Exceeded (4), Exceeded (4), Nearly Met (2), Not Met (1) | 11 | 2.75 | 83 |
| Exceeded (4), Met (3), Met (3), Not Met (1) | 11 | 2.75 | 83 |
| Exceeded (4), Met (3), Nearly Met (2), Nearly Met (2) | 11 | 2.75 | 83 |
| Met (3), Met (3), Met (3), Nearly Met (2) | 11 | 2.75 | 83 |
| Exceeded (4), Exceeded (4), Not Met (1), Not Met (1) | 10 | 2.50 | 75 |
| Exceeded (4), Met (3), Nearly Met (2), Not Met (1) | 10 | 2.50 | 75 |
| Exceeded (4), Nearly Met (2), Nearly Met (2), Nearly Met (2) | 10 | 2.50 | 75 |
| Met (3), Met (3), Met (3), Not Met (1) | 10 | 2.50 | 75 |
| Met (3), Met (3), Nearly Met (2), Nearly Met (2) | 10 | 2.50 | 75 |
| Exceeded (4), Met (3), Not Met (1), Not Met (1) | 9 | 2.25 | 68 |
| Exceeded (4), Nearly Met (2), Nearly Met (2), Not Met (1) | 9 | 2.25 | 68 |
| Met (3), Met (3), Nearly Met (2), Not Met (1) | 9 | 2.25 | 68 |
| Met (3), Nearly Met (2), Nearly Met (2), Nearly Met (2) | 9 | 2.25 | 68 |
| Exceeded (4), Nearly Met (2), Not Met (1), Not Met (1) | 8 | 2.00 | 60 |
| Met (3), Met (3), Not Met (1), Not Met (1) | 8 | 2.00 | 60 |
| Met (3), Nearly Met (2), Nearly Met (2), Not Met (1) | 8 | 2.00 | 60 |
| Nearly Met (2), Nearly Met (2), Nearly Met (2), Nearly Met (2) | 8 | 2.00 | 60 |
| Exceeded (4), Not Met (1), Not Met (1), Not Met (1) | 7 | 1.75 | 53 |
| Met (3), Nearly Met (2), Not Met (1), Not Met (1) | 7 | 1.75 | 53 |
| Nearly Met (2), Nearly Met (2), Nearly Met (2), Not Met (1) | 7 | 1.75 | 53 |
| Met (3), Not Met (1), Not Met (1), Not Met (1) | 6 | 1.50 | 45 |
| Nearly Met (2), Nearly Met (2), Not Met (1), Not Met (1) | 6 | 1.50 | 45 |
| Nearly Met (2), Not Met (1), Not Met (1), Not Met (1) | 5 | 1.25 | 38 |
| Not Met (1), Not Met (1), Not Met (1), Not Met (1) | 4 | 1.00 | 30 |

---

## Appendix 3: Support Professional – Professional Practice Rubric

[This section contains the detailed rubrics for each component. The full rubric text is preserved below, organized by component.]

### The Rubric At A Glance

| **DOMAIN 1: COLLABORATION** | **DOMAIN 2: SERVICE DELIVERY** |
|--------------------------|------------------------------|
| **A.** Works with educators and families to develop strategies and resources to meet the needs of students | **A.** Establishes service delivery and/or program goals and develops a plan to evaluate them |
| **B.** Uses and models effective communication with learners, colleagues and/or stakeholders | **B.** Plans effectively for service delivery that is based on student data and knowledge of child development |
| **C.** Builds rapport with students promoting effective service delivery | **C.** Implements service delivery that is student focused ensuring students have greater ownership in their education and well being |
| **D.** Demonstrates flexibility and responsiveness | **D.** Uses appropriate assessments to diagnose or identify and monitor student issues or programmatic progress and to adjust service/program delivery |

---

## Appendix 4: Support Professional - Professional Responsibilities Rubric

[This section contains the detailed Professional Responsibilities rubrics. The text is preserved below, organized by component.]

### The Rubric at a Glance

| **DOMAIN 1: SCHOOL RESPONSIBILITIES AND COMMUNICATION** | **DOMAIN 2: PROFESSIONALISM** | **DOMAIN 3: PROFESSIONAL GROWTH** |
|-----------------------------------------------------|--------------------------|------------------------------|
| **PR1:** Understands and participates in school/district-based initiatives and activities<br>• Knowledge of school and district initiatives and activities<br>• Involvement in school and district initiatives and activities | **PR3:** Acts on the belief that all students can learn and advocates for students' best interests<br>• Interactions with students<br>• Interactions with parents<br>• Course offerings<br>• Support service offerings<br>• Student advocacy meeting<br>• Call notes<br>• After school support logs | **PR6:** Engages meaningfully in school and district professional growth opportunities and enhances professional growth by giving and seeking assistance from other educators in order to improve student learning<br>• Interactions with colleagues<br>• Involvement in professional growth opportunities |
| **PR2:** Solicits, maintains records of, and communicates appropriate information about students' behavior, learning needs, and academic progress<br>• Interactions with parents<br>• Interactions with colleagues<br>• Student or personnel records<br>• Grade books/Service notes<br>• Specialist referrals<br>• Maintains appropriate level of confidentiality<br>• Implements systems of communication | **PR4:** Works toward a safe, supportive, collaborative culture by demonstrating respect for everyone, including other educators, students, parents, and other community members in all actions and interactions<br>• Interactions with colleagues<br>• Interactions with students<br>• Interactions with parents<br>• Interactions with community members | **PR7:** Writes and implements a Professional Growth Goal that addresses personal, school, or district needs and aims at improving the support professional's practice<br>• Professional Growth Goal(s)<br>• Log of professional learning activities related to goal(s)<br>• Training materials, handouts, agendas, materials<br>• Interactions with colleagues<br>• Demonstration of practice |
| | **PR5:** Acts ethically and with integrity while following all school, district, and state policies<br>• Required personnel file documentation of behavior<br>• Interactions with school leadership<br>• Interactions with colleagues<br>• Interactions with students, families, and outside providers | |

---

[The detailed scoring rubrics for each component follow with Level 1-4 descriptions, critical attributes, and possible examples. Due to length, these are included in the comprehensive markdown above.]